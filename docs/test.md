# DevOps Co-pilot 测试用例文档

> 版本：v1.0  
> 更新日期：2025-12-19  
> 状态：Draft

---

## 目录

1. [测试策略](#1-测试策略)
2. [场景识别测试用例](#2-场景识别测试用例)
3. [翻译质量测试用例](#3-翻译质量测试用例)
4. [流式输出测试用例](#4-流式输出测试用例)
5. [异常边界测试用例](#5-异常边界测试用例)
6. [端到端测试场景](#6-端到端测试场景)

---

## 1. 测试策略

### 1.1 测试层次

```
┌─────────────────────────────────────────────────────────────┐
│                        测试金字塔                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│                      ┌─────────┐                            │
│                      │  E2E    │  端到端测试（Playwright）   │
│                      │  Tests  │  覆盖完整用户流程           │
│                     ─┴─────────┴─                           │
│                   ┌───────────────┐                         │
│                   │  Integration  │  集成测试               │
│                   │    Tests      │  API 接口测试            │
│                  ─┴───────────────┴─                        │
│                ┌───────────────────────┐                    │
│                │      Unit Tests       │  单元测试           │
│                │                       │  工具函数、组件      │
│               ─┴───────────────────────┴─                   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 测试重点

| 测试类型 | 重点内容 | 验收标准 |
|---------|---------|---------|
| **场景识别** | 业务/技术语言识别准确性 | 准确率 ≥ 95% |
| **翻译质量** | 输出维度完整性、内容价值 | 覆盖所有预定义维度 |
| **流式输出** | 实时性、稳定性 | 首字符 ≤ 2秒，无中断 |
| **异常处理** | 错误提示友好性 | 用户可理解、可操作 |

### 1.3 测试环境

> **重要**：所有测试均使用**真实环境 + 真实 API**，不使用 Mock。

| 配置项 | 值 |
|-------|-----|
| 环境 | 本地开发环境（`npm run dev`） |
| LLM API | DeepSeek API（真实调用） |
| 数据存储 | 本地 `sessions/` 目录 |
| 浏览器 | Playwright MCP 控制的真实浏览器 |

```bash
# 启动测试环境
npm run dev

# 确保 .env 配置
DEEPSEEK_API_KEY=sk-xxx
DEEPSEEK_BASE_URL=https://api.deepseek.com
```

### 1.4 E2E 测试执行方式（Playwright MCP 实操）

> **说明**：E2E 测试通过 **Playwright MCP** 由 AI 助手实操执行，真实打开浏览器，从用户视角进行验证。

#### 执行方式

```
┌─────────────────────────────────────────────────────────────┐
│                   Playwright MCP 实操测试                    │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   AI 助手通过 Playwright MCP 工具：                          │
│                                                             │
│   1. browser_navigate  → 打开应用页面                        │
│   2. browser_snapshot  → 获取页面结构                        │
│   3. browser_type      → 在输入框输入内容                    │
│   4. browser_click     → 点击按钮                            │
│   5. browser_snapshot  → 观察输出结果                        │
│   6. browser_take_screenshot → 截屏记录                      │
│                                                             │
│   整个过程从用户视角真实操作浏览器                            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 测试执行流程

```
1. 启动项目: npm run dev（用户执行）
2. AI 实操测试:
   - 打开浏览器访问 localhost:3000
   - 按照测试用例进行真实操作
   - 观察输出内容和页面变化
   - 截屏记录关键节点
3. 结果评估:
   - AI 分析输出是否符合预期
   - 如不符合，结合日志定位问题
```

#### 可用的 Playwright MCP 工具

| 工具 | 用途 |
|-----|------|
| `browser_navigate` | 导航到指定 URL |
| `browser_snapshot` | 获取页面快照（DOM 结构） |
| `browser_click` | 点击页面元素 |
| `browser_type` | 在元素中输入文本 |
| `browser_take_screenshot` | 截取页面截图 |
| `browser_wait_for` | 等待文本出现/消失 |
| `browser_tabs` | 管理浏览器标签页 |

### 1.5 测试结果评估标准

| 评估等级 | 标准 | 说明 |
|---------|------|------|
| ✅ **符合预期** | 所有断言通过，产出覆盖预期维度 | Case 通过 |
| ⭐ **超出预期** | 产出不仅覆盖维度，还有额外有价值的信息 | 优秀 |
| ⚠️ **部分符合** | 核心断言通过，但产出质量有提升空间 | 需要优化 Prompt |
| ❌ **不符合预期** | 断言失败，或产出明显偏离预期 | 需要排查问题 |

### 1.6 日志辅助问题排查

> **重要说明**：日志不是用来"验证日志输出没输出"的，而是当测试结果不符合预期时，辅助定位问题的工具。

#### 日志格式

```
2025-12-19 10:49:34.494 [INFO ] [abc123] TranslateAPI - Request received
2025-12-19 10:49:34.512 [DEBUG] [abc123] SceneRecognizer - Analyzing input: "..."
2025-12-19 10:49:34.520 [INFO ] [abc123] SceneRecognizer - Recognition result: business
2025-12-19 10:49:34.892 [INFO ] [abc123] LLMClient - Stream started, model: deepseek
2025-12-19 10:49:36.123 [INFO ] [abc123] LLMClient - Stream completed, tokens: 523
2025-12-19 10:49:36.456 [INFO ] [abc123] TranslateAPI - Request completed, duration: 1962ms
```

#### 问题排查流程

```
┌─────────────────────────────────────────────────────────────┐
│                   测试结果不符合预期                          │
└─────────────────────────┬───────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 1: 查看测试输出的 console.log                          │
│  - 确认输入是否正确发送                                       │
│  - 确认输出内容是什么                                         │
└─────────────────────────┬───────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 2: 查看后端日志                                        │
│  - 场景识别结果是否正确？                                     │
│    → 如果识别错误，可能是识别逻辑或 Prompt 问题               │
│  - LLM 调用是否成功？                                        │
│    → 如果失败，检查 API Key 或网络                           │
│  - 上下文是否正确传入？                                       │
│    → 如果上下文丢失，检查 Session 管理逻辑                   │
└─────────────────────────┬───────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 3: 定位问题根因                                        │
├─────────────────────────────────────────────────────────────┤
│  • 识别错误 → 优化 Prompt 中的识别规则                       │
│  • 翻译维度不全 → 优化 Prompt 中的输出要求                   │
│  • 翻译质量差 → 调整 Prompt 示例或增加约束                   │
│  • 上下文未利用 → 检查上下文拼接逻辑                         │
│  • 超时/报错 → 检查 API 配置或网络                           │
└─────────────────────────────────────────────────────────────┘
```

#### 关键日志检查点

| 检查点 | 日志关键词 | 正常情况 | 异常情况 |
|-------|----------|---------|---------|
| 请求入口 | `Request received` | 有此日志 | 无日志=请求未到达 |
| 场景识别 | `Recognition result` | `business` 或 `technical` | `insufficient` 或 `unrecognized` |
| 上下文加载 | `Context loaded` | `turns: N` | `turns: 0` = 上下文丢失 |
| LLM 调用 | `Stream started` | 有此日志 | 无日志=调用未发起 |
| LLM 完成 | `Stream completed` | `tokens: N` | 无日志=流中断 |
| 会话持久化 | `Turn persisted` | 有此日志 | 无日志=存储失败 |

---

## 2. 场景识别测试用例

### 2.1 业务语言识别（产品→开发）

| 用例ID | 输入 | 预期识别结果 | 优先级 |
|-------|------|------------|-------|
| SR-001 | 我们需要一个智能推荐功能，提升用户停留时长 | 【产品→开发】 | P0 |
| SR-002 | 用户希望能够一键分享到微信朋友圈 | 【产品→开发】 | P0 |
| SR-003 | 这个功能是为了提升新用户的转化率 | 【产品→开发】 | P0 |
| SR-004 | 我们想要一个会员积分系统 | 【产品→开发】 | P0 |
| SR-005 | 能不能实现扫码登录功能？ | 【产品→开发】 | P0 |
| SR-006 | 目标是让DAU提升20% | 【产品→开发】 | P1 |
| SR-007 | 需要支持多语言切换 | 【产品→开发】 | P1 |
| SR-008 | 用户反馈页面加载太慢了 | 【产品→开发】 | P1 |

### 2.2 技术语言识别（开发→产品）

| 用例ID | 输入 | 预期识别结果 | 优先级 |
|-------|------|------------|-------|
| SR-101 | 我们优化了数据库查询，QPS提升了30% | 【开发→产品】 | P0 |
| SR-102 | 通过引入Redis缓存，接口响应时间从500ms降到50ms | 【开发→产品】 | P0 |
| SR-103 | 完成了用户服务的微服务拆分 | 【开发→产品】 | P0 |
| SR-104 | 修复了一个导致内存泄漏的Bug | 【开发→产品】 | P0 |
| SR-105 | 实现了消息队列的异步处理机制 | 【开发→产品】 | P0 |
| SR-106 | 数据库索引优化后，慢查询减少了80% | 【开发→产品】 | P1 |
| SR-107 | 部署了新的监控告警系统 | 【开发→产品】 | P1 |
| SR-108 | 重构了登录模块，支持OAuth2.0协议 | 【开发→产品】 | P1 |

### 2.3 边界情况识别

| 用例ID | 输入 | 预期识别结果 | 说明 |
|-------|------|------------|------|
| SR-201 | 我们需要优化搜索功能，用户说太慢了 | 【产品→开发】 | 业务目标引出技术需求 |
| SR-202 | 通过CDN优化，用户感觉页面快多了 | 【开发→产品】 | 技术成果说明用户影响 |
| SR-203 | 登录功能 | 【信息不足】 | 极简输入，需追问 |
| SR-204 | API重构 | 【信息不足】 | 极简输入，需追问 |

### 2.4 容错识别（无法识别场景）

| 用例ID | 输入 | 预期识别结果 | 说明 |
|-------|------|------------|------|
| SR-301 | 今天天气怎么样 | 【无法识别】 | 与产品/开发无关 |
| SR-302 | 帮我写个测试用例 | 【无法识别】 | QA 领域内容 |
| SR-303 | K8s 怎么部署 | 【无法识别】 | 运维领域/知识问答 |
| SR-304 | 什么是机器学习 | 【无法识别】 | 通用知识问答 |
| SR-305 | 明天的会议几点开始 | 【无法识别】 | 日程/闲聊 |

### 2.5 信息不足识别

| 用例ID | 输入 | 预期识别结果 | 预期追问方向 |
|-------|------|------------|-------------|
| SR-401 | 优化一下 | 【信息不足】 | 优化什么？从哪个角度？ |
| SR-402 | 用户体验不好 | 【信息不足】 | 具体哪里不好？什么场景？ |
| SR-403 | 性能问题 | 【信息不足】 | 什么性能？指标是什么？ |
| SR-404 | 做个功能 | 【信息不足】 | 什么功能？解决什么问题？ |
| SR-405 | 报错了 | 【信息不足】 | 什么报错？什么场景下？ |

---

## 3. 翻译质量测试用例

### 3.1 产品→开发 翻译质量

#### TQ-001：智能推荐功能

**输入**：
```
我们需要一个智能推荐功能，提升用户停留时长
```

**验收标准**：

| 维度 | 必须包含 | 检查项 |
|-----|---------|-------|
| 技术方案概述 | ✓ | 至少提供2种技术方案（如协同过滤、内容推荐） |
| 数据与依赖 | ✓ | 说明需要的数据类型和来源 |
| 工作量评估 | ✓ | 给出复杂度评估和时间预估 |
| 技术风险 | ✓ | 指出至少2个潜在风险 |
| 待确认问题 | ✓ | 提出至少2个需要产品澄清的问题 |

#### TQ-002：一键分享功能

**输入**：
```
用户希望能够一键分享到微信朋友圈
```

**验收标准**：

| 维度 | 必须包含 | 检查项 |
|-----|---------|-------|
| 技术方案概述 | ✓ | 提及微信SDK、分享参数配置 |
| 数据与依赖 | ✓ | 提及微信开放平台接入 |
| 工作量评估 | ✓ | 给出合理的时间预估 |
| 技术风险 | ✓ | 提及审核风险、平台限制等 |
| 待确认问题 | ✓ | 询问分享内容、样式等 |

### 3.2 开发→产品 翻译质量

#### TQ-101：数据库优化

**输入**：
```
我们优化了数据库查询，QPS提升了30%
```

**验收标准**：

| 维度 | 必须包含 | 检查项 |
|-----|---------|-------|
| 用户体验影响 | ✓ | 翻译为用户可感知的变化（更快） |
| 业务价值 | ✓ | 说明支撑的业务增长空间 |
| 成本与效率 | ✓ | 提及可能的成本节省 |
| 可宣传亮点 | ✓ | 提供一句话汇报总结 |
| 后续可能性 | ✓ | 说明为未来打开的可能性 |

#### TQ-102：缓存优化

**输入**：
```
通过引入Redis缓存，接口响应时间从500ms降到50ms
```

**验收标准**：

| 维度 | 必须包含 | 检查项 |
|-----|---------|-------|
| 用户体验影响 | ✓ | 翻译为"页面加载快了10倍" |
| 业务价值 | ✓ | 关联到用户满意度、留存 |
| 成本与效率 | ✓ | 数据库压力降低等 |
| 可宣传亮点 | ✓ | 简洁有力的汇报语 |
| 后续可能性 | ✓ | 缓存架构的扩展性 |

---

## 4. 流式输出测试用例

### 4.1 性能测试

| 用例ID | 测试项 | 验收标准 | 测试方法 |
|-------|-------|---------|---------|
| ST-001 | 首字符延迟 | ≤ 2秒 | 计时器测量 |
| ST-002 | 流式连续性 | 无明显卡顿 | 视觉观察 |
| ST-003 | 完整响应时间 | ≤ 30秒（普通输入） | 计时器测量 |

### 4.2 稳定性测试

| 用例ID | 测试项 | 验收标准 | 测试方法 |
|-------|-------|---------|---------|
| ST-101 | 长文本输入 | 正常完成流式输出 | 输入1000字符 |
| ST-102 | 连续请求 | 不互相干扰 | 快速连续发起请求 |
| ST-103 | 中断恢复 | 已输出内容保留 | 网络中断测试 |

---

## 5. 异常边界测试用例

### 5.1 输入验证

| 用例ID | 输入 | 预期结果 | 优先级 |
|-------|------|---------|-------|
| EX-001 | （空输入） | 提示"请输入内容" | P0 |
| EX-002 | "  "（纯空格） | 提示"请输入有效内容" | P0 |
| EX-003 | 超过5000字符 | 提示"内容过长，请精简" | P0 |
| EX-004 | 特殊字符 `<script>` | 正常处理，不执行 | P1 |
| EX-005 | 纯数字 "12345" | 正常识别和翻译 | P1 |
| EX-006 | 英文输入 | 正常识别和翻译 | P1 |

### 5.2 API 错误处理

| 用例ID | 模拟场景 | 预期提示 | 优先级 |
|-------|---------|---------|-------|
| EX-101 | LLM API 超时 | "AI服务暂时不可用，请稍后重试" | P0 |
| EX-102 | LLM API Key 无效 | "系统配置错误，请联系管理员" | P0 |
| EX-103 | 网络断开 | "网络连接失败，请检查网络" | P0 |
| EX-104 | 速率限制 | "请求过于频繁，请稍后再试" | P1 |

### 5.3 UI 交互

| 用例ID | 操作 | 预期行为 | 优先级 |
|-------|------|---------|-------|
| EX-201 | 翻译中点击按钮 | 按钮禁用，防止重复提交 | P0 |
| EX-202 | 翻译中修改输入 | 不影响当前翻译 | P1 |
| EX-203 | 快速连续点击 | 只处理一次请求 | P1 |

---

## 6. 端到端测试场景（Playwright MCP 实操）

> **执行方式**：AI 助手通过 Playwright MCP 工具真实操作浏览器，从用户视角验证功能。

### 6.1 典型用户流程

#### E2E-001：产品经理使用流程

```
场景：产品经理输入业务需求，验证翻译成技术语言

输入内容：
"我们需要一个智能推荐功能，提升用户停留时长"

操作步骤：
1. browser_navigate → 打开 http://localhost:3000
2. browser_snapshot → 获取页面结构
3. browser_type → 在输入框输入上述内容
4. browser_click → 点击"开始翻译"按钮
5. browser_wait_for → 等待翻译完成
6. browser_snapshot → 观察输出结果
7. browser_take_screenshot → 截屏记录

验收标准：
✓ 识别结果显示【产品→开发】
✓ 翻译内容包含：技术方案概述
✓ 翻译内容包含：数据与依赖
✓ 翻译内容包含：工作量评估
✓ 翻译内容包含：技术风险
✓ 翻译内容包含：待确认问题
✓ 按钮恢复可用状态
```

#### E2E-002：开发工程师使用流程

```
场景：开发工程师输入技术成果，验证翻译成业务语言

输入内容：
"我们优化了数据库查询，QPS提升了30%"

操作步骤：
1. browser_navigate → 打开 http://localhost:3000
2. browser_type → 在输入框输入上述内容
3. browser_click → 点击"开始翻译"按钮
4. browser_wait_for → 等待翻译完成
5. browser_snapshot → 观察输出结果

验收标准：
✓ 识别结果显示【开发→产品】
✓ 翻译内容包含：用户体验影响
✓ 翻译内容包含：业务价值
✓ 翻译内容包含：成本与效率
✓ 翻译内容包含：可宣传亮点
✓ 翻译内容包含：后续可能性
```

#### E2E-003：产品场景 - 业务指标驱动的需求

```
场景：产品经理以业务指标为驱动提出需求

输入内容：
"我们要把DAU从10万提升到15万，需要做一个用户激励体系"

操作步骤：
1. browser_navigate → 打开页面
2. browser_type → 输入上述内容
3. browser_click → 点击翻译
4. browser_snapshot → 观察输出

验收标准：
✓ 识别结果显示【产品→开发】
✓ 翻译覆盖5个维度
✓ 内容质量：应提到积分/签到/任务等具体激励手段（不是空泛的建议）
```

#### E2E-004：产品场景 - 用户反馈问题

```
场景：产品经理基于用户反馈提出优化需求

输入内容：
"用户反馈说首页加载太慢了，经常要等5秒以上，很多人直接退出了"

操作步骤：同 E2E-001

验收标准：
✓ 识别结果显示【产品→开发】
✓ 翻译覆盖5个维度
✓ 内容质量：应提到缓存/CDN/懒加载/首屏优化等具体技术方案
```

#### E2E-005：开发场景 - 架构改造成果

```
场景：开发工程师汇报架构改造成果

输入内容：
"我们完成了订单服务的微服务拆分，从单体应用中独立出来，支持独立部署和扩容"

操作步骤：同 E2E-001

验收标准：
✓ 识别结果显示【开发→产品】
✓ 翻译覆盖5个维度
✓ 内容质量：应翻译成产品能理解的价值（稳定/可靠/大促支撑/扩展能力）
```

#### E2E-006：开发场景 - Bug修复成果

```
场景：开发工程师汇报 Bug 修复成果

输入内容：
"修复了一个严重的内存泄漏问题，之前服务每隔3天就要重启一次，现在可以稳定运行了"

操作步骤：同 E2E-001

验收标准：
✓ 识别结果显示【开发→产品】
✓ 翻译覆盖5个维度
✓ 内容质量：应翻译成用户可感知的影响（稳定/不会中断/7x24可用）
```

### 6.2 多轮对话流程

#### E2E-201：信息不足追问流程

```
场景：用户输入信息不足，系统追问后再翻译

第1轮输入：
"登录功能"

第2轮输入（补充信息）：
"需要支持手机号和微信登录，提升新用户注册转化率"

操作步骤：
1. browser_navigate → 打开页面
2. browser_type → 输入"登录功能"
3. browser_click → 点击翻译
4. browser_snapshot → 观察输出（应显示追问）
5. browser_type → 输入补充信息
6. browser_click → 再次点击翻译
7. browser_snapshot → 观察输出（应显示翻译结果）

验收标准：
✓ 第1轮：显示追问提示，而非强行翻译
✓ 第2轮：识别为【产品→开发】，正常翻译
✓ 会话历史：显示两轮对话记录
```

#### E2E-202：多人协作流程 - 产品开发对话

```
场景：产品和开发在同一会话中交替对话

第1轮输入（产品）：
"我们需要一个评论功能"

第2轮输入（开发）：
"我们实现了评论功能，支持多级回复，QPS可达1000"

操作步骤：
1. browser_navigate → 打开页面
2. browser_type → 输入产品需求
3. browser_click → 点击翻译
4. browser_snapshot → 验证【产品→开发】
5. browser_type → 输入开发成果
6. browser_click → 点击翻译
7. browser_snapshot → 验证【开发→产品】且关联上下文

验收标准：
✓ 第1轮：识别为【产品→开发】
✓ 第2轮：识别为【开发→产品】
✓ 上下文关联：第2轮输出应关联"评论"这个上下文
```

#### E2E-203：关闭浏览器后恢复上下文继续对话（核心场景）

```
场景：关闭浏览器后重新打开，基于历史上下文继续对话

【第一阶段：创建会话并对话】

第1轮输入：
"我们要做一个直播带货功能，用户可以边看直播边下单"

操作步骤：
1. browser_navigate → 打开页面
2. browser_type → 输入上述内容
3. browser_click → 点击翻译
4. browser_snapshot → 验证【产品→开发】
5. browser_take_screenshot → 截屏记录第1轮

【第二阶段：关闭页面，模拟关闭浏览器】

操作步骤：
6. browser_close → 关闭当前页面
7. browser_navigate → 重新打开页面

【第三阶段：验证历史自动加载】

操作步骤：
8. browser_snapshot → 验证历史对话已回显（应包含"直播带货"）

【第四阶段：基于上下文继续对话】

第2轮输入：
"我们完成了直播推流模块的开发，延迟控制在500ms以内"

操作步骤：
9. browser_type → 输入上述内容
10. browser_click → 点击翻译
11. browser_snapshot → 观察输出
12. browser_take_screenshot → 截屏记录

验收标准：
✓ 关闭再打开后，历史对话自动回显
✓ 第2轮识别为【开发→产品】
✓ 关键：第2轮输出应关联"直播带货"业务场景（验证上下文被利用）
```

#### E2E-204：围绕一个需求的长对话（研发管理全流程）

```
场景：围绕"用户标签系统"需求，产品和开发进行5轮对话

【第1轮：产品提出初步需求】
输入："我们想做一个用户标签系统，给用户打标签"
预期：可能触发追问（信息不足）或直接翻译

【第2轮：产品补充需求细节】
输入："标签用于个性化推荐和精准营销，需要支持自动标签和手动标签，目标是提升广告点击率20%"
预期：识别为【产品→开发】，翻译应包含技术方案

【第3轮：开发给出技术评估】
输入："我们评估了一下，自动标签需要接入用户行为数据和机器学习模型，预计需要3周。手动标签1周可以完成。建议先做手动标签MVP"
预期：识别为【开发→产品】，翻译成产品能理解的语言

【第4轮：产品确认方案】
输入："同意先做手动标签，下个迭代再做自动标签。手动标签需要支持运营在后台批量打标签"
预期：识别为【产品→开发】

【第5轮：开发完成后汇报】
输入："手动标签功能开发完成，支持批量导入、单个打标、标签分组，后台页面响应时间<200ms"
预期：识别为【开发→产品】，结合上下文翻译成业务价值

操作步骤：
1. browser_navigate → 打开页面
2-4. 循环5轮：browser_type → browser_click → browser_snapshot
5. 每轮截屏记录

验收标准：
✓ 5轮对话都正确识别场景
✓ 产品→开发翻译包含技术方案维度
✓ 开发→产品翻译包含业务价值维度
✓ 后续轮次结合上下文（提到营销/推荐/广告/标签）
✓ 会话历史显示5轮对话记录
```

### 6.3 会话管理流程

#### E2E-301：首次使用流程

```
场景：首次打开应用，验证会话自动创建

前置条件：清空 sessions/ 目录

操作步骤：
1. browser_navigate → 打开页面
2. browser_snapshot → 验证 [+] 按钮置灰
3. browser_type → 输入"我们需要一个搜索功能"
4. browser_click → 点击翻译
5. browser_wait_for → 等待翻译完成
6. browser_snapshot → 验证 [+] 按钮变为可用

验收标准：
✓ 首次进入，[+] 按钮置灰
✓ 可以直接输入，不需要先点击 [+]
✓ 第一次查询后，会话持久化到磁盘
✓ [+] 按钮变为可用
```

#### E2E-301b：创建新会话

```
场景：已有会话后，点击 [+] 创建新会话

操作步骤：
1. browser_navigate → 打开页面
2. browser_type → 输入内容并翻译
3. browser_click → 点击 [+] 按钮
4. browser_snapshot → 验证界面清空

验收标准：
✓ 点击 [+] 后，输入框清空
✓ 历史对话区域清空
✓ 可以开始新的对话
```

#### E2E-302：历史会话回显

```
场景：刷新页面后，验证历史会话自动加载

操作步骤：
1. browser_navigate → 打开页面
2. browser_type → 输入"智能推荐功能"
3. browser_click → 点击翻译
4. browser_wait_for → 等待完成
5. browser_navigate → 刷新页面（重新打开）
6. browser_snapshot → 验证历史内容回显

验收标准：
✓ 刷新后，自动加载最新会话
✓ 历史对话内容完整显示
```

### 6.4 容错场景 E2E 测试

#### E2E-401：无法识别的输入

```
场景：输入与产品/开发无关的内容

输入内容：
"今天天气怎么样"

操作步骤：
1. browser_navigate → 打开页面
2. browser_type → 输入上述内容
3. browser_click → 点击翻译
4. browser_snapshot → 观察输出

验收标准：
✓ 显示友好提示，不强行翻译
✓ 不包含【产品→开发】或【开发→产品】
✓ 给出使用建议或引导
```

#### E2E-402：边界输入处理

```
场景A：空输入
输入内容：不输入任何内容
预期：显示"请输入"提示

场景B：超长输入
输入内容：5000字符以上的内容
预期：正确处理或给出提示

操作步骤：同 E2E-001

验收标准：
✓ 空输入时有明确提示
✓ 超长输入不会崩溃
```

### 6.5 上下文能力验证

#### E2E-501：上下文对翻译质量的影响

```
场景：对比有无上下文时，相同输入的翻译质量差异

【场景A：无上下文直接翻译】

输入内容：
"需要支持多种登录方式"

操作步骤：
1. browser_navigate → 打开页面（新会话）
2. browser_type → 输入上述内容
3. browser_click → 点击翻译
4. browser_snapshot → 记录输出A

【场景B：有上下文再翻译】

第1轮输入（提供上下文）：
"我们在做一个企业内部办公系统，需要员工登录后才能使用"

第2轮输入（同样的需求）：
"需要支持多种登录方式"

操作步骤：
5. browser_navigate → 打开页面（新会话）
6. browser_type → 输入第1轮内容
7. browser_click → 点击翻译
8. browser_type → 输入第2轮内容
9. browser_click → 点击翻译
10. browser_snapshot → 记录输出B

【对比验证】

验收标准：
✓ 输出B比输出A更具体
✓ 输出B应提到"企业"、"员工"、"内部"、"SSO"、"LDAP"等关键词
✓ 证明上下文被有效利用
```

---

## 7. 容错测试用例

### 7.1 无法识别处理

| 用例ID | 输入 | 预期输出 | 验收标准 |
|-------|------|---------|---------|
| FT-001 | 今天天气怎么样 | 友好提示 | 明确告知不在处理范围，给出建议 |
| FT-002 | 帮我写首诗 | 友好提示 | 不强行翻译，引导正确使用 |
| FT-003 | 123456 | 友好提示/追问 | 根据情况追问或提示 |

### 7.2 追问质量

| 用例ID | 输入 | 预期追问 | 验收标准 |
|-------|------|---------|---------|
| FT-101 | 登录功能 | 询问场景、目标、范围 | 追问问题具体、有针对性 |
| FT-102 | 优化一下 | 询问优化什么、从哪个角度 | 追问问题不超过3个 |
| FT-103 | 用户体验不好 | 询问具体场景、什么不好 | 给出选项而非开放问题 |

---

## 8. 会话管理测试用例

### 8.1 会话生命周期

| 用例ID | 操作 | 预期结果 | 优先级 |
|-------|------|---------|-------|
| SM-001 | 创建新会话 | 生成 Session ID，创建 .md 文件 | P0 |
| SM-002 | 添加对话轮次 | .md 文件正确追加内容 | P0 |
| SM-003 | 读取会话历史 | 正确解析 .md 文件内容 | P0 |
| SM-004 | 切换会话 | 正确加载对应会话上下文 | P1 |

### 8.2 上下文传递

| 用例ID | 场景 | 验收标准 | 优先级 |
|-------|------|---------|-------|
| SM-101 | 第2轮翻译 | 第1轮内容作为上下文传入 | P0 |
| SM-102 | 第3轮翻译 | 前2轮内容作为上下文传入 | P0 |
| SM-103 | 上下文影响翻译 | 有上下文的翻译比无上下文更精准 | P0 |

### 8.3 存储完整性

| 用例ID | 场景 | 验收标准 | 优先级 |
|-------|------|---------|-------|
| SM-201 | Markdown 格式 | 文件格式正确，可被正确解析 | P0 |
| SM-202 | 特殊字符 | 输入含特殊字符时正确存储 | P1 |
| SM-203 | 长文本 | 长输入正确存储，不截断 | P1 |

---

## 附录

### A. 测试数据集

为便于批量测试，提供以下测试数据：

```json
{
  "businessInputs": [
    "我们需要一个智能推荐功能，提升用户停留时长",
    "用户希望能够一键分享到微信朋友圈",
    "这个功能是为了提升新用户的转化率",
    "我们想要一个会员积分系统",
    "能不能实现扫码登录功能？"
  ],
  "techInputs": [
    "我们优化了数据库查询，QPS提升了30%",
    "通过引入Redis缓存，接口响应时间从500ms降到50ms",
    "完成了用户服务的微服务拆分",
    "修复了一个导致内存泄漏的Bug",
    "实现了消息队列的异步处理机制"
  ]
}
```

### B. 测试检查清单

```markdown
## 发布前检查清单

### 功能测试
- [ ] SR-001 ~ SR-008 业务语言识别通过
- [ ] SR-101 ~ SR-108 技术语言识别通过
- [ ] SR-301 ~ SR-305 无法识别场景通过
- [ ] SR-401 ~ SR-405 信息不足识别通过
- [ ] TQ-001 ~ TQ-002 产品→开发翻译质量通过
- [ ] TQ-101 ~ TQ-102 开发→产品翻译质量通过

### 性能测试
- [ ] ST-001 首字符延迟 ≤ 2秒
- [ ] ST-002 流式输出无卡顿

### 异常测试
- [ ] EX-001 ~ EX-006 输入验证通过
- [ ] EX-101 ~ EX-104 错误处理通过

### 容错测试
- [ ] FT-001 ~ FT-003 无法识别处理通过
- [ ] FT-101 ~ FT-103 追问质量通过

### 会话管理测试
- [ ] SM-001 ~ SM-004 会话生命周期通过
- [ ] SM-101 ~ SM-103 上下文传递通过
- [ ] SM-201 ~ SM-203 存储完整性通过

### 端到端测试（Playwright）

**典型用户流程**
- [ ] E2E-001 产品经理使用流程通过
- [ ] E2E-002 开发工程师使用流程通过
- [ ] E2E-003 业务指标驱动需求通过
- [ ] E2E-004 用户反馈问题通过
- [ ] E2E-005 架构改造成果通过
- [ ] E2E-006 Bug修复成果通过

**多轮对话流程**
- [ ] E2E-201 信息不足追问流程通过
- [ ] E2E-202 多人协作流程通过
- [ ] E2E-203 关闭浏览器后恢复上下文通过（核心）
- [ ] E2E-204 围绕一个需求的长对话通过（核心）

**会话管理流程**
- [ ] E2E-301 首次使用自动创建会话通过
- [ ] E2E-302 历史会话回显通过

**容错场景**
- [ ] E2E-401 无法识别输入友好提示通过
- [ ] E2E-402 边界输入处理通过

**上下文能力验证**
- [ ] E2E-501 有无上下文对翻译质量的影响验证通过
```

---

*文档结束*

